import json
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage

load_dotenv()

def generate_questions_with_gemini():
    with open("app/data/extended_questions.json", "r", encoding="utf-8") as f:
        extended_questions = json.load(f)

    def build_prompt(questions):
        prompt = "D·ª±a tr√™n c√°c c√¢u h·ªèi d∆∞·ªõi ƒë√¢y, h√£y t·∫°o th√™m 3 c√¢u h·ªèi t∆∞∆°ng t·ª±.\n"
        for i, q in enumerate(questions, 1):
            prompt += f"C√¢u {i}: {q['question']}\n"
            for opt_key, opt_val in q["options"].items():
                prompt += f"  {opt_key}. {opt_val}\n"
            prompt += f"ƒê√°p √°n: {q['answer']}\nCh·ªß ƒë·ªÅ: {q['topic']}\n\n"
        prompt += "\nüëâ Tr·∫£ l·ªùi b·∫±ng JSON."
        return prompt

    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=os.getenv("GOOGLE_API_KEY"))
    prompt = build_prompt(extended_questions)
    response = llm.invoke([HumanMessage(content=prompt)])
    return {"result": response.content}