from pymongo import MongoClient
from datetime import datetime
import os
from dotenv import load_dotenv
from pinecone import Pinecone
from langchain_pinecone import PineconeVectorStore
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.chat_history import InMemoryChatMessageHistory
from fpdf import FPDF

# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()
store = {}

# K·∫øt n·ªëi Mongo
mongo_uri = os.getenv("MONGO_URI")
client = MongoClient(mongo_uri)
db = client["upskill_db"]
chat_collection = db["chat_history"]

def get_session_history(session_id):
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]

def generate_questions_from_material(user_id, course_id, question, topic=None):
    namespace = f"{user_id}-{course_id}"
    history = get_session_history(namespace)

    # Pinecone setup
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    index = pc.Index("upskill")
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = PineconeVectorStore(index=index, embedding=embeddings, namespace=namespace)

    docs = vectorstore.similarity_search(topic or question, k=20)

    print("üìÑ T√†i li·ªáu li√™n quan:")
    for i, doc in enumerate(docs, 1):
        print(f"\n--- T√†i li·ªáu {i} ---")
        print("üîπ Metadata:", doc.metadata)
        print("üî∏ N·ªôi dung:", doc.page_content[:300], "...")

    context = "\n\n".join([d.page_content for d in docs]) if docs else "Kh√¥ng c√≥ n·ªôi dung."

    template = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω h·ªçc t·∫≠p. D·ª±a v√†o t√†i li·ªáu sau, h√£y t·∫°o ra m·ªôt danh s√°ch c√°c c√¢u h·ªèi luy·ªán t·∫≠p cho ng∆∞·ªùi h·ªçc, t·∫≠p trung v√†o n·ªôi dung ch√≠nh, c√≥ th·ªÉ ki·ªÉm tra m·ª©c ƒë·ªô hi·ªÉu c·ªßa h·ªçc vi√™n.

L∆∞u √Ω:
- C√¢u h·ªèi n√™n ng·∫Øn g·ªçn, r√µ r√†ng.
- N·∫øu ph√π h·ª£p, c√≥ th·ªÉ bao g·ªìm c·∫£ c√¢u h·ªèi tr·∫Øc nghi·ªám v√† t·ª± lu·∫≠n.

T√ÄI LI·ªÜU:
{context}

L·ªäCH S·ª¨ T∆Ø∆†NG T√ÅC TR∆Ø·ªöC (n·∫øu c√≥):
{history}
"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", template),
        ("human", "{user_question}")
    ])

    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=os.getenv("GOOGLE_API_KEY"))

    chain = (
        {
            "context": lambda _: context,
            "history": lambda _: "\n".join([m.content for m in history.messages]),
            "user_question": lambda _: question
        }
        | prompt
        | llm
        | StrOutputParser()
    )

    result = chain.invoke({})

    # Check ƒë√£ c√≥ document ch∆∞a
    existing_doc = chat_collection.find_one({
        "user_id": user_id,
        "course_id": course_id
    })

    if existing_doc:
        # T√≠nh id m·ªõi
        next_id = len(existing_doc.get("history", [])) + 1
        chat_collection.update_one(
            {"_id": existing_doc["_id"]},
            {
                "$push": {
                    "history": {
                        "id": next_id,
                        "question": question,
                        "answer": result
                    }
                },
                "$set": {"timestamp": datetime.utcnow()}
            }
        )
    else:

        chat_collection.insert_one({
            "user_id": user_id,
            "course_id": course_id,
            "history": [
                {
                    "id": 1,
                    "question": question,
                    "answer": result
                }
            ],
            "timestamp": datetime.utcnow()
        })

    return {"questions": result}


def export_history_to_txt(user_id: str, course_id: str, output_path: str = "chat_history.txt"):
    record = chat_collection.find_one({
        "user_id": user_id,
        "course_id": course_id
    })

    if not record or "history" not in record:
        print("‚ùå Kh√¥ng c√≥ l·ªãch s·ª≠ n√†o ƒë·ªÉ xu·∫•t.")
        return

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(f"L·ªäCH S·ª¨ H·ªåC T·∫¨P - {user_id.upper()} ({course_id.upper()})\n\n")

        for entry in record["history"]:
            f.write(f"C√¢u h·ªèi {entry['id']}:\n")
            f.write(f"C√ÇU H·ªéI: {entry['question']}\n")
            f.write(f"TR·∫¢ L·ªúI: {entry['answer']}\n")
            if "timestamp" in entry:
                f.write(f"Th·ªùi gian: {entry['timestamp']}\n")
            f.write("\n" + "-"*40 + "\n\n")

    print(f"‚úÖ ƒê√£ xu·∫•t TXT: {output_path}")


def main():
    result = generate_questions_from_material(
        user_id="kiet1",
        course_id="Transactions",
            question="T·∫°o b·ªô c√¢u h·ªèi 10 c√¢u tr·∫Øc nghi·ªám Lesson 1: Overview of Transactions and Locks v·ªÅ Transactions v√† Locked trong Microsoft SQL Server.",
            topic="Transactions"
    )

    print("\n========== C√ÇU H·ªéI SINH RA ==========")
    print(result["questions"])

if __name__ == "__main__":
    main()
    export_history_to_txt(user_id="kiet1", course_id="Transactions", output_path="transactions_chat_history.txt")
